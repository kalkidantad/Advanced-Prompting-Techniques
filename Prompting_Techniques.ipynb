{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -U google-generativeai"
      ],
      "metadata": {
        "collapsed": true,
        "id": "EPJ0dXwipeOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "ftgLFrUTdpP-"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai\n",
        "from collections import Counter\n",
        "from IPython.display import Markdown"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up Gemini-Pro API key\n",
        "genai.configure(api_key=\"gemini-key\")\n"
      ],
      "metadata": {
        "id": "Vcf7K6AFd_Dz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The set_gemini_params function that allows to configure the Gemini-2.0-flash model with customizable parameters:\n",
        "\n",
        "\n",
        "Temperature: Controls randomness (lower = deterministic, higher = diverse outputs).\n",
        "\n",
        "Top_p: Nucleus sampling, controlling probability mass selection.\n",
        "\n",
        "Frequency & Presence Penalty: Modify token repetition behavior."
      ],
      "metadata": {
        "id": "UQhh7bNOXBw7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def set_gemini_params(\n",
        "    model='gemini-2.0-flash',\n",
        "    temperature=0.7,\n",
        "    top_p=1,\n",
        "    frequency_penalty=0,\n",
        "    presence_penalty=0,\n",
        "):\n",
        "    \"\"\"Set Gemini-2.0-flash parameters.\"\"\"\n",
        "    params = {\n",
        "        \"model\": model,\n",
        "        \"temperature\": temperature,\n",
        "        \"top_p\": top_p,\n",
        "        \"frequency_penalty\": frequency_penalty,\n",
        "        \"presence_penalty\": presence_penalty,\n",
        "    }\n",
        "    return params"
      ],
      "metadata": {
        "id": "DcC8QCIPeAsq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_completion(params, prompt):\n",
        "    \"\"\"Get completion from Gemini-2.0-flash API.\"\"\"\n",
        "    try:\n",
        "        model_name = params[\"model\"]\n",
        "        model = genai.GenerativeModel(model_name)\n",
        "        response = model.generate_content(\n",
        "            prompt,\n",
        "            generation_config={\n",
        "                \"temperature\": params[\"temperature\"],\n",
        "                \"top_p\": params[\"top_p\"],\n",
        "            },\n",
        "        )\n",
        "        return response.text if hasattr(response, \"text\") else \"No response received.\"\n",
        "    except Exception as e:\n",
        "        return f\"Error: {e}\"\n"
      ],
      "metadata": {
        "id": "1yQaYdz8eAjp"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Few Shot Prompting\n",
        "\n"
      ],
      "metadata": {
        "id": "nC1zudr2elEk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Purpose: Provides examples to guide the model’s response style.\n",
        "\n",
        "Uses a low temperature (0.3) to ensure accuracy and consistency.\n",
        "\n",
        "It responds translation task."
      ],
      "metadata": {
        "id": "JwKfa7jJXRJy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def few_shot():\n",
        "    \"\"\"Few-shot prompting \"\"\"\n",
        "    instructions = \"Translate the following English sentences to French.\"\n",
        "    context = \"Here are some examples:\\n1. English: Hello, how are you? French: Bonjour, comment ça va?\\n2. English: I love programming. French: J'adore la programmation.\"\n",
        "    input_data = \"English: The weather is nice today.\"\n",
        "    output_indicator = \"French:\"\n",
        "    prompt = f\"{instructions}\\n{context}\\n{input_data}\\n{output_indicator}\"\n",
        "\n",
        "\n",
        "    params = set_gemini_params(temperature=0.3)  # Low temperature for deterministic output\n",
        "    response = get_completion(params, prompt)\n",
        "    display(Markdown(response))\n"
      ],
      "metadata": {
        "id": "AcHJh0AweAb9"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    few_shot()"
      ],
      "metadata": {
        "id": "1F1V84TIeAMB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "e6ce657a-8413-4be6-dace-f9f65928976f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Il fait beau aujourd'hui.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Chain of Thought"
      ],
      "metadata": {
        "id": "oKhMr8pis_lu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Zero-shot Chain-of-Thought (CoT) Prompting"
      ],
      "metadata": {
        "id": "0DTIKHYjXhh_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Purpose: Encourages step-by-step reasoning without examples.\n",
        "\n",
        "* Works well for simple logical problems."
      ],
      "metadata": {
        "id": "ZryZBUX5Xoli"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def zero_shot_cot():\n",
        "    \"\"\"Zero-shot chain-of-thought example.\"\"\"\n",
        "    instructions = \"Solve the following math problem step by step.\"\n",
        "    context = \"\"\n",
        "    input_data = \"If a car travels 60 miles in 1 hour, how far will it travel in 3 hours?\"\n",
        "    output_indicator = \"Let's think step by step:\"\n",
        "    prompt = f\"{instructions}\\n{context}\\n{input_data}\\n{output_indicator}\"\n",
        "\n",
        "    params = set_gemini_params(temperature=0.3)  # Focus on logical consistency rather than unnecessary\n",
        "    response = get_completion(params, prompt)\n",
        "    display(Markdown(response))"
      ],
      "metadata": {
        "id": "hRkWjKyDeABs"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    zero_shot_cot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "Tzoq6HMetSty",
        "outputId": "6f1e5008-b2b5-48df-af4d-0eaa706ebce1"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "1. **Find the speed:** The car travels 60 miles in 1 hour, so its speed is 60 miles per hour (mph).\n\n2. **Calculate the distance:** To find the distance traveled in 3 hours, multiply the speed by the time: 60 mph * 3 hours = 180 miles.\n\n**Answer:** The car will travel 180 miles in 3 hours.\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Few-shot Chain-of-Thought (CoT) Prompting"
      ],
      "metadata": {
        "id": "RNxXhjCCYAVE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Purpose: Enhances reasoning by using prior structured examples."
      ],
      "metadata": {
        "id": "hcDs17ThYGI6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def few_shot_cot():\n",
        "    \"\"\"Few-shot chain-of-thought example.\"\"\"\n",
        "    instructions = \"Solve the following math problem step by step.\"\n",
        "    context = \"\"\"\n",
        "Here are some examples:\n",
        "1. Problem: If a car travels 60 miles in 1 hour, how far will it travel in 3 hours?\n",
        "   Solution: Let's think step by step:\n",
        "   - The car travels 60 miles in 1 hour.\n",
        "   - To find the distance traveled in 3 hours, multiply the speed by the time.\n",
        "   - 60 miles/hour * 3 hours = 180 miles.\n",
        "   Answer: 180 miles.\n",
        "\n",
        "2. Problem: If a train travels 120 kilometers in 2 hours, how far will it travel in 5 hours?\n",
        "   Solution: Let's think step by step:\n",
        "   - The train travels 120 kilometers in 2 hours.\n",
        "   - First, find the speed: 120 km / 2 hours = 60 km/hour.\n",
        "   - To find the distance traveled in 5 hours, multiply the speed by the time.\n",
        "   - 60 km/hour * 5 hours = 300 kilometers.\n",
        "   Answer: 300 kilometers.\n",
        "\"\"\"\n",
        "    input_data = \"Problem: If a cyclist travels 30 kilometers in 1 hour, how far will they travel in 4 hours?\"\n",
        "    output_indicator = \"Solution: \"\n",
        "    prompt = f\"{instructions}\\n{context}\\n{input_data}\\n{output_indicator}\"\n",
        "\n",
        "    params = set_gemini_params(temperature=0.3)  # Low temperature for deterministic output\n",
        "    response = get_completion(params, prompt)\n",
        "    display(Markdown(response))"
      ],
      "metadata": {
        "id": "wlCPqopbTCLM"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    few_shot_cot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "OE0siVDJTE-g",
        "outputId": "404319f4-7a85-4612-ba1c-7b379c42589f"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "- The cyclist travels 30 kilometers in 1 hour.\n- To find the distance traveled in 4 hours, multiply the speed by the time.\n- 30 kilometers/hour * 4 hours = 120 kilometers.\nAnswer: 120 kilometers.\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Self-Consistency\n"
      ],
      "metadata": {
        "id": "n6VHt1SSt3uq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Purpose: Runs multiple completions and selects the most frequent output.\n",
        "\n",
        "* Temperature kept at 0.3 to minimize randomness.\n",
        "\n",
        "* Uses Counter to identify the most common response."
      ],
      "metadata": {
        "id": "8tYPa9qHYRE5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def self_consistency():\n",
        "    \"\"\"Self consistency \"\"\"\n",
        "    instructions = \"Answer the following question with a single, direct answer.\"\n",
        "    context = \"\"\n",
        "    input_data = \"Question: What is the most poisonous insect?\"\n",
        "    output_indicator = \"Answer:\"\n",
        "    prompt = f\"{instructions}\\n{context}\\n{input_data}\\n{output_indicator}\"\n",
        "\n",
        "    params = set_gemini_params(temperature=0.3)  # Lower temperature for focused output\n",
        "\n",
        "    # Generate multiple responses\n",
        "    responses = []\n",
        "    for _ in range(5):  # Generate 5 responses\n",
        "        response = get_completion(params, prompt)\n",
        "        responses.append(response)\n",
        "\n",
        "    # Determine the most consistent answer\n",
        "    most_common_answer = Counter(responses).most_common(1)[0][0]\n",
        "\n",
        "    display(Markdown(\"### Generated Responses:\"))\n",
        "    for i, response in enumerate(responses, 1):\n",
        "        display(Markdown(f\"**Response {i}:** {response}\"))\n",
        "\n",
        "    # Display the most consistent answer\n",
        "    display(Markdown(f\"\\n**Most Consistent Answer:** {most_common_answer}\"))\n"
      ],
      "metadata": {
        "id": "GV3sTz5wt3LD"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "  self_consistency()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "J39PL_wZuCjv",
        "outputId": "231ea7a2-3136-4a18-acd6-b63f2c1919a2"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Generated Responses:"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Response 1:** The most poisonous insect is debated, but the **poison dart frog** is often cited as the most poisonous animal, and while not an insect, its poison is derived from insects in its diet.\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Response 2:** The most poisonous insect is the **blister beetle**.\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Response 3:** The most poisonous insect is debated, but the **blister beetle** is often cited due to its cantharidin content.\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Response 4:** The most poisonous insect is generally considered to be the **blister beetle**.\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Response 5:** The most poisonous insect is generally considered to be the **blister beetle**.\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n**Most Consistent Answer:** The most poisonous insect is generally considered to be the **blister beetle**.\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Generate Knowledge"
      ],
      "metadata": {
        "id": "t5GdU06B060M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Purpose: Generates knowledge first, then uses it to answer a question.\n",
        "\n",
        "\n",
        "*   Multi-step response generation.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "W8TM-b5eYaBz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_knowledge_dual_prompt():\n",
        "    \"\"\"Generate knowledge about AI in healthcare and use it to answer a question.\"\"\"\n",
        "    # Step 1: Generate short background knowledge about Cloud Computing in Inventory Management\n",
        "    instructions = \"Generate concise background knowledge about the role of Cloud Computing in inventory management.\"\n",
        "    context = \"\"\n",
        "    input_data = \"Topic: Cloud Computing in Inventory Management\"\n",
        "    output_indicator = \"Knowledge:\"\n",
        "    prompt = f\"{instructions}\\n{context}\\n{input_data}\\n{output_indicator}\"\n",
        "\n",
        "    params = set_gemini_params(temperature=0.5)  # Moderate temperature since the goal is exploratory content\n",
        "    knowledge = get_completion(params, prompt)\n",
        "\n",
        "    # Step 2: Use the generated knowledge to answer a specific question\n",
        "    instructions = \"Answer the question using the provided knowledge.\"\n",
        "    context = f\"Knowledge: {knowledge}\"\n",
        "    input_data = \"Question: What are the key advantages of Cloud Computing in Inventory management?\"\n",
        "    output_indicator = \"Answer:\"\n",
        "    prompt = f\"{instructions}\\n{context}\\n{input_data}\\n{output_indicator}\"\n",
        "\n",
        "    response = get_completion(params, prompt)\n",
        "\n",
        "    print(\"Background Knowledge\")\n",
        "    display(Markdown(knowledge))\n",
        "    print(\"Answer\")\n",
        "    display(Markdown(response))"
      ],
      "metadata": {
        "id": "SqShzDk21Cms"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    generate_knowledge_dual_prompt()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "VdfvbIf-1FLd",
        "outputId": "584708cf-c906-4171-dd6f-7ad8cac9bae2"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Background Knowledge\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Cloud computing offers scalable, accessible, and cost-effective solutions for inventory management. It enables real-time visibility across the supply chain, improves forecasting accuracy, streamlines warehouse operations, and facilitates better decision-making through data analytics, all without the need for extensive on-premise infrastructure.\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The key advantages of Cloud Computing in inventory management are:\n\n*   **Scalability:** Easily adjust resources to meet changing inventory needs.\n*   **Accessibility:** Access inventory data from anywhere with an internet connection.\n*   **Cost-effectiveness:** Reduces the need for expensive on-premise infrastructure.\n*   **Real-time visibility:** Provides up-to-date information across the supply chain.\n*   **Improved forecasting accuracy:** Enables better prediction of future demand.\n*   **Streamlined warehouse operations:** Optimizes processes within the warehouse.\n*   **Better decision-making:** Facilitates informed choices through data analytics.\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5. Program-Aided"
      ],
      "metadata": {
        "id": "AUyvwSEZ2IfL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Purpose: Debugs code by prompting the model for corrections.\n",
        "\n",
        "* Fixes logical and syntax errors in Python."
      ],
      "metadata": {
        "id": "Hxn2GM2eY-kd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def program_aided():\n",
        "    \"\"\"Program-aided language model for debugging Python code.\"\"\"\n",
        "    instructions = \"Find and fix the bug in the following Python function.\"\n",
        "    context = \"def divide(a, b):\\n    return a / b\\n\\nprint(divide(5, 0))\"\n",
        "    output_indicator = \"Corrected code:\"\n",
        "    prompt = f\"{instructions}\\n{context}\\n{output_indicator}\"\n",
        "\n",
        "    params = set_gemini_params(temperature=0.3)\n",
        "    response = get_completion(params, prompt)\n",
        "    display(Markdown(response))"
      ],
      "metadata": {
        "id": "32OiZ0Fn2Hw7"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    program_aided()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "wHFllp5n2UJU",
        "outputId": "fca8e85e-c352-4125-97a1-9d65d773e9e7"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "```python\ndef divide(a, b):\n    if b == 0:\n        return \"Cannot divide by zero\"\n    return a / b\n\nprint(divide(5, 0))\n```\n\n**Reasoning:**\n\nThe original code does not handle the case where `b` is zero, which will cause a `ZeroDivisionError`. The corrected code adds a check to see if `b` is zero. If it is, it returns an error message. Otherwise, it performs the division as before. This prevents the program from crashing and provides a more informative response to the user.\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}